{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74451e1",
   "metadata": {},
   "source": [
    "# Scrape ESPN Fantasy Football League Utility Notebook <a id=\"return\"></a>\n",
    "\n",
    "This notebook contains all the dictionaries and all the functions used in the 00-scrape_espn_ff_api_v3.ipynb notebook.\n",
    "<br><br/>\n",
    "\n",
    "**Notebook Sections:**\n",
    "1. [Import Packages](#section1)\n",
    "2. [Create Dictionaries for Owner Names, NFL Team Names, Scoring Codes, etc.](#section2)\n",
    "3. [Functions for Data Ingestion](#section3)\n",
    "4. [Functions for Rosters Dataframe](#section4)\n",
    "5. [Functions for Matchups Dataframe](#section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680045de",
   "metadata": {},
   "source": [
    "## Import Packages <a id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13e3734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width of this notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d51f3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import needed packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re, requests, bs4, csv, datetime\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edc926b",
   "metadata": {},
   "source": [
    "## Create Dictionaries for Owner Names, NFL Team Names, Scoring Codes, etc. <a id=\"section2\"></a>\n",
    "\n",
    "This section creates dictionaries for:\n",
    "1. Fantasy Football Owner Team Codes\n",
    "2. Lineup Slot Codes\n",
    "3. Position Codes\n",
    "4. NFL Team Codes\n",
    "5. NFL Player Stat Codes\n",
    "6. Fantasy Football Scoring Codes\n",
    "7. Fantasy Football Scoring Values (likely won't need to use or modify)\n",
    "<br><br/>\n",
    "\n",
    "Need player stat codes for:\n",
    "* FG 60+ yards\n",
    "* fumble recovered for td vs. fumble return for TD?\n",
    "<br><br/>\n",
    "\n",
    "Source: https://github.com/mkreiser/ESPN-Fantasy-Football-API/blob/master/src/player-stats/player-stats.js\n",
    "<br><br/>\n",
    "\n",
    "[Return to Top](#return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of owner ids, owner team names, and owner names\n",
    "owner_team_codes = {1:  ['Happy Rock Homewreckers', 'Blainer'],               \n",
    "                    2:  [\"Bench Don't Kill My Vibe\", 'Padge'],\n",
    "                    4:  ['Seattle rainier riot', 'Boob'],\n",
    "                    6:  ['Sticky Icky', 'T-$'],\n",
    "                    7:  ['Springfield Atoms', 'Duvi'],\n",
    "                    8:  ['Beacon Hill Posterizers', 'Bup'],\n",
    "                    9:  ['Brookside Shokunin', 'Cheese'], \n",
    "                    10: ['CoMo FightinCamlToes', 'Doisy'],\n",
    "                    11: ['Pixel Whippers','Sembower'],\n",
    "                    15: ['Bud Lathrop Drive', 'Farmer']\n",
    "}\n",
    "\n",
    "# create dictionary of lineup slot ids and lineup names\n",
    "lineup_slot_codes = {0:  'QB',\n",
    "                     2:  'RB',\n",
    "                     3:  'Flex',\n",
    "                     4:  'WR',\n",
    "                     6:  'TE', \n",
    "                     16: 'Def', \n",
    "                     17: 'K',\n",
    "                     20: 'Bench', \n",
    "                     21: 'IR',\n",
    "                     23: 'Flex'\n",
    "}\n",
    "\n",
    "# create dictionary of position ids and position names\n",
    "position_codes = {1:  'QB',\n",
    "                  2:  'RB',\n",
    "                  3:  'WR',\n",
    "                  4:  'TE',\n",
    "                  5:  'KR',\n",
    "                  16: 'DEF'\n",
    "    \n",
    "}\n",
    "\n",
    "# create dictionary of team ids and team names\n",
    "pro_team_codes = {0:  ['Free Agent', np.nan],\n",
    "                  1:  ['Atlanta Falcons', 'ATL'],\n",
    "                  2:  ['Buffalo Bills', 'BUF'],\n",
    "                  3:  ['Chicago Bears', 'CHI'],\n",
    "                  4:  ['Cincinnati Bengals', 'CIN'],\n",
    "                  5:  ['Cleveland Browns', 'CLE'],\n",
    "                  6:  ['Dallas Cowboys', 'DAL'],\n",
    "                  7:  ['Denver Broncs', 'DEN'],\n",
    "                  8:  ['Detroit Lions', 'DET'],\n",
    "                  9:  ['Greenbay Packers', 'GB'],\n",
    "                  10: ['Tennessee Titans', 'TEN'],\n",
    "                  11: ['Indianapolis Colts', 'IND'],\n",
    "                  12: ['Kansas City Chiefs', 'KC'],\n",
    "                  13: ['Las Vegas Raiders', 'LV'],\n",
    "                  14: ['Los Angeles Rams', 'LA'],\n",
    "                  15: ['Miami Dolphins', 'MIA'],\n",
    "                  16: ['Minnesota Vikings', 'MIN'],\n",
    "                  17: ['New Engalnd Patriots', 'NE'],\n",
    "                  18: ['New Orleans Saints', 'NO'],\n",
    "                  19: ['New York Giants', 'NYG'],\n",
    "                  20: ['New York Jets', 'NYJ'],\n",
    "                  21: ['Philadelphia Eagles', 'PHI'],\n",
    "                  22: ['Arizona Cardinals', 'ARI'],\n",
    "                  23: ['Pittsburgh Steelers', 'PIT'],\n",
    "                  24: ['Los Angeles Chargers', 'LAC'],\n",
    "                  25: ['San Francisco 49ers', 'SF'],\n",
    "                  26: ['Seattle Seahawks', 'SEA'],\n",
    "                  27: ['Tampa Bay Buccaneers', 'TB'],\n",
    "                  28: ['Washington Commanders', 'WAS'],\n",
    "                  29: ['Carolina Panthers', 'CAR'],\n",
    "                  30: ['Jacksonville Jaguars', 'JAX'],\n",
    "                  33: ['Baltimore Ravens', 'BAL'],\n",
    "                  34: ['Houston Texans', 'HOU']\n",
    "}\n",
    "\n",
    "# create dictionary of real game statistics codes\n",
    "player_stat_codes = {0:   'pass_att',\n",
    "                     1:   'pass_comp',\n",
    "                     2:   'pass_incomp',\n",
    "                     3:   'pass_yrd',\n",
    "                     4:   'pass_td',\n",
    "                     5:   'pass_5_yrd',\n",
    "                     6:   'unk6',\n",
    "                     7:   'unk7',\n",
    "                     8:   'unk8',\n",
    "                     9:   'unk9',\n",
    "                     10:  'unk10',\n",
    "                     11:  'unk11',\n",
    "                     12:  'unk12',\n",
    "                     13:  'unk13',\n",
    "                     14:  'unk14',\n",
    "                     15:  'unk15',\n",
    "                     16:  'pass_50_yrd_td',\n",
    "                     17:  'pass_yrd_300_399',\n",
    "                     18:  'pass_yrd_400+',\n",
    "                     19:  'unk19',\n",
    "                     19:  'pass_2pt_con',\n",
    "                     20:  'pass_int',\n",
    "                     21:  'unk21',\n",
    "                     22:  'pass_yrd_dupe',\n",
    "                     23:  'rush_att',\n",
    "                     24:  'rush_yrd',\n",
    "                     25:  'rush_td',\n",
    "                     26:  'rush_2pt_con',\n",
    "                     27:  'rush_5_yrd',\n",
    "                     28:  'unk28',\n",
    "                     29:  'unk29',\n",
    "                     30:  'unk30',\n",
    "                     31:  'unk31',\n",
    "                     32:  'unk32',\n",
    "                     33:  'unk33',\n",
    "                     34:  'unk34',\n",
    "                     35:  'unk35',\n",
    "                     36:  'rush_50_yrd_td',\n",
    "                     37:  'rush_yrd_100_199',\n",
    "                     38:  'rush_yrd_200+',\n",
    "                     39:  'unk39',\n",
    "                     40:  'unk40',\n",
    "                     41:  'receptions_dupe',\n",
    "                     42:  'rec_yrd',\n",
    "                     43:  'rec_td',\n",
    "                     44:  'rec_2pt_con',\n",
    "                     45:  'unk45',\n",
    "                     46:  'rec_50_yrd_td',\n",
    "                     47:  'rec_5_yrd',\n",
    "                     48:  'unk48',\n",
    "                     49:  'unk49',\n",
    "                     50:  'unk50',\n",
    "                     51:  'unk51',\n",
    "                     52:  'unk52',\n",
    "                     53:  'receptions',\n",
    "                     54:  'unk54',\n",
    "                     55:  'unk55',\n",
    "                     56:  'rec_yrd_100_199',\n",
    "                     57:  'rec_yrd_200+',\n",
    "                     58:  'rec_tar',\n",
    "                     59:  'yac',\n",
    "                     60:  'yrd_per_rec',\n",
    "                     61:  'rec_yrd_dupe',\n",
    "                     62:  'unk62',\n",
    "                     64:  'unk64',\n",
    "                     65:  'unk65',\n",
    "                     66:  'unk66',\n",
    "                     67:  'unk67',\n",
    "                     68:  'unk68',\n",
    "                     69:  'unk69',\n",
    "                     70:  'unk70',\n",
    "                     71:  'unk71',\n",
    "                     72:  'fum_lost',\n",
    "                     73:  'unk73',\n",
    "                     74:  'fg_made_50+',\n",
    "                     75:  'unk75',\n",
    "                     76:  'unk76',\n",
    "                     77:  'fg_made_40_49',\n",
    "                     78:  'unk78',\n",
    "                     79:  'fg_miss_40_49',\n",
    "                     80:  'fg_made_0_39',\n",
    "                     81:  'unk81',\n",
    "                     82:  'fg_miss_0_39',\n",
    "                     83:  'fg_con',\n",
    "                     84:  'fg_att',  \n",
    "                     85:  'fg_miss_tot',\n",
    "                     86:  'pat_con',\n",
    "                     87:  'pat_att',\n",
    "                     88:  'pat_miss_tot',\n",
    "                     89:  'def_st_0_pts_alw',\n",
    "                     90:  'def_st_1_6_pts_alw',\n",
    "                     91:  'def_st_7_13_pts_alw',\n",
    "                     92:  'def_st_14_17_pts_alw',\n",
    "                     93:  'def_st_blk_td',\n",
    "                     94:  'unk94',\n",
    "                     95:  'def_st_int',\n",
    "                     96:  'def_st_fum',\n",
    "                     97:  'def_st_blk_kick',\n",
    "                     98:  'def_st_safety',\n",
    "                     99:  'def_st_sack',\n",
    "                     100: 'unk100',\n",
    "                     101: 'def_st_kick_ret_td',\n",
    "                     102: 'def_st_punt_ret_td',\n",
    "                     103: 'def_st_int_td',\n",
    "                     104: 'def_st_fum_ret_td',\n",
    "                     105: 'unk105',\n",
    "                     106: 'unk106',\n",
    "                     107: 'unk107',\n",
    "                     108: 'unk108',\n",
    "                     109: 'unk109',\n",
    "                     110: 'unk110',\n",
    "                     111: 'unk111',\n",
    "                     112: 'unk112',\n",
    "                     113: 'unk113',\n",
    "                     114: 'unk114',\n",
    "                     115: 'unk115',\n",
    "                     116: 'unk116',\n",
    "                     117: 'unk117',\n",
    "                     118: 'unk118',\n",
    "                     119: 'unk119',\n",
    "                     120: 'def_pts_alw',\n",
    "                     121: 'unk121',\n",
    "                     122: 'def_st_22_27_pts_alw',\n",
    "                     123: 'def_st_28_34_pts_alw',\n",
    "                     124: 'def_st_35_45_pts_alw',\n",
    "                     125: 'def_st_46+_pts_alw',\n",
    "                     127: 'def_tot_yrd_alw',\n",
    "                     128: 'def_st_0_99_yrd_alw',\n",
    "                     129: 'def_st_100_199_yrd_alw',\n",
    "                     130: 'def_st_200_299_yrd_alw',\n",
    "                     131: 'unk131',\n",
    "                     132: 'def_st_350_399_yrd_alw',\n",
    "                     133: 'def_st_400_449_yrd_alw',\n",
    "                     134: 'def_st_450_499_yrd_alw',\n",
    "                     135: 'def_st_500_549_yrd_alw',\n",
    "                     136: 'def_st_550+_yrd_alw',\n",
    "                     155: 'unk155',\n",
    "                     156: 'unk156',\n",
    "                     158: 'unk158',\n",
    "                     175: 'unk175',\n",
    "                     176: 'unk176',\n",
    "                     177: 'unk177',\n",
    "                     178: 'unk178',\n",
    "                     179: 'unk179',\n",
    "                     180: 'unk180',\n",
    "                     181: 'unk181',\n",
    "                     182: 'unk182',\n",
    "                     183: 'unk183',\n",
    "                     184: 'unk184',\n",
    "                     185: 'unk185',\n",
    "                     186: 'unk186',\n",
    "                     187: 'unk187',\n",
    "                     188: 'unk188',\n",
    "                     189: 'unk189',\n",
    "                     190: 'unk190',\n",
    "                     191: 'unk191',\n",
    "                     192: 'unk192',\n",
    "                     193: 'unk193',\n",
    "                     194: 'unk194',\n",
    "                     195: 'unk195',\n",
    "                     196: 'unk196',\n",
    "                     197: 'unk197',\n",
    "                     198: 'fg_made_50_59',\n",
    "                     199: 'unk199',\n",
    "                     200: 'unk200',\n",
    "                     202: 'unk202',\n",
    "                     203: 'unk203',\n",
    "                     210: 'unk210',\n",
    "}\n",
    "\n",
    "# create dictionary of fantasy football specific statistics codes\n",
    "ff_scoring_codes = {1:   'pass_comp_ff',\n",
    "                    2:   'pass_incomp_ff',\n",
    "                    4:   'pass_td_ff',\n",
    "                    5:   'pass_5_yrd_ff',\n",
    "                    16:  'pass_50_yrd_td_ff',\n",
    "                    17:  'pass_yrd_300_399_ff',\n",
    "                    18:  'pass_yrd_400+_ff',\n",
    "                    19:  'pass_2pt_con_ff',\n",
    "                    20:  'pass_int_ff',\n",
    "                    25:  'rush_td_ff',\n",
    "                    26:  'rush_2pt_con_ff',\n",
    "                    27:  'rush_5_yrd_ff',\n",
    "                    36:  'rush_50_yrd_td_ff',\n",
    "                    37:  'rush_yrd_100_199_ff',\n",
    "                    38:  'rush_yrd_200+_ff',\n",
    "                    43:  'rec_td_ff',\n",
    "                    44:  'rec_2pt_con_ff_ff',\n",
    "                    46:  'rec_50_yrd_td_ff',\n",
    "                    47:  'rec_5_yrd_ff',\n",
    "                    53:  'receptions_ff',\n",
    "                    56:  'rec_yrd_100_199_ff',\n",
    "                    57:  'rec_yrd_200+_ff',\n",
    "                    72:  'fum_lost_ff',\n",
    "                    77:  'fg_made_40_49_ff',\n",
    "                    79:  'fg_miss_40_49_ff',\n",
    "                    80:  'fg_made_0_39_ff',\n",
    "                    82:  'fg_miss_0_39_ff',\n",
    "                    86:  'pat_made_ff',\n",
    "                    88:  'pat_miss_ff',\n",
    "                    89:  'def_st_0_pts_alw_ff',\n",
    "                    90:  'def_st_1_6_pts_alw_ff',\n",
    "                    91:  'def_st_7_13_pts_alw_ff',\n",
    "                    92:  'def_st_14_17_pts_alw_ff',\n",
    "                    93:  'def_st_blk_td_ff',\n",
    "                    95:  'def_st_int_ff',\n",
    "                    96:  'def_st_fum_ff',\n",
    "                    97:  'def_st_blk_kick_ff',\n",
    "                    98:  'def_st_safety_ff',\n",
    "                    99:  'def_st_sack_ff',\n",
    "                    101: 'def_st_kick_ret_td_ff',\n",
    "                    102: 'def_st_punt_ret_td_ff',\n",
    "                    103: 'def_st_int_td_ff',\n",
    "                    104: 'def_st_fum_ret_td_ff',\n",
    "                    122: 'def_st_22_27_pts_alw_ff',\n",
    "                    123: 'def_st_28_34_pts_alw_ff',\n",
    "                    124: 'def_st_35_45_pts_alw_ff',\n",
    "                    125: 'def_st_46+_pts_alw_ff',\n",
    "                    128: 'def_st_0_99_yrd_alw_ff',\n",
    "                    129: 'def_st_100_199_yrd_alw_ff',\n",
    "                    130: 'def_st_200_299_yrd_alw_ff',\n",
    "                    132: 'def_st_350_399_yrd_alw_ff',\n",
    "                    133: 'def_st_400_449_yrd_alw_ff',\n",
    "                    134: 'def_st_450_499_yrd_alw_ff',\n",
    "                    135: 'def_st_500_549_yrd_alw_ff',\n",
    "                    136: 'def_st_550+_yrd_alw_ff',\n",
    "                    198: 'fg_made_50_59_ff'\n",
    "}\n",
    "\n",
    "# create dictionary of fantasy football scoring values\n",
    "scoring_dict = {'pass_5_yrd':            0.1,\n",
    "                'pass_comp':             0.4,\n",
    "                'pass_incomp':           -0.2,\n",
    "                'pass_td':                6,\n",
    "                'pass_50_yrd_td':         3,\n",
    "                'pass_int':               -2,\n",
    "                'pass_2pt_con':           2,\n",
    "                'pass_yrd_300_399':       3,\n",
    "                'P400':                   5,\n",
    "                'rush_5_yrd':             0.6,\n",
    "                'rush_td':                6,\n",
    "                'RTD50':                  3,\n",
    "                'rush_2pt_con':           2,\n",
    "                'rush_yrd_100_199':       3,\n",
    "                'RY200':                  5,\n",
    "                'rec_5_yrd':              0.6,\n",
    "                'receptions':             1,\n",
    "                'rec_td':                 6,\n",
    "                'rec_50_yrd_td':          3,\n",
    "                'rec_2pt_con':            2,\n",
    "                'rec_yrd_100_199':        3,\n",
    "                'REY200':                 5,\n",
    "                'pat_made':               1,\n",
    "                'pat_miss':               -1,\n",
    "                'fg_made_0_39':           3,\n",
    "                'fg_made_40_49':          4,\n",
    "                'fg_miss_0_39':           -2,\n",
    "                'fg_miss_40_49':          -1,\n",
    "                'fg_made_50':             5,\n",
    "                'FG60':                   5,\n",
    "                'def_st_kick_ret_td':     6,\n",
    "                'def_st_punt_ret_td':     6,\n",
    "                'def_st_int_td':          5,\n",
    "                'def_st_fum_ret_td':      5,\n",
    "                'def_st_blk_td':          6,\n",
    "                'def_st_sack':            1,\n",
    "                'def_st_blk_kick':        2,\n",
    "                'def_st_int':             3,\n",
    "                'def_st_fum':             3,\n",
    "                'def_st_safety':          2,\n",
    "                'def_st_0_pts_alw':       10,\n",
    "                'def_st_1_6_pts_alw':     7,\n",
    "                'def_st_7_13_pts_alw':    3,\n",
    "                'def_st_14_17_pts_alw':   1,\n",
    "                'def_st_22_27_pts_alw':   -1,\n",
    "                'def_st_28_34_pts_alw':   -3,\n",
    "                'def_st_35_45_pts_alw':   -5,\n",
    "                'PA46':                   -7,\n",
    "                'def_st_0_99_yrd_alw':    7,\n",
    "                'def_st_100_199_yrd_alw': 3,\n",
    "                'def_st_200_299_yrd_alw': 1,\n",
    "                'def_st_400_449_yrd_alw': -1,\n",
    "                'def_st_450_499_yrd_alw': -1.5,\n",
    "                'def_st_500_549_yrd_alw': -2,\n",
    "                'def_st_550+_yrd_alw':    -3,\n",
    "                'misc_kick_ret_td':       6,\n",
    "                'misc_punt_ret_td':       6,\n",
    "                'misc_fum_rec_td':        6,\n",
    "                'misc_fum_lost':          -2,\n",
    "                'misc_fum_ret_td':        6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382b140",
   "metadata": {},
   "source": [
    "## Functions for Data Ingestion <a id=\"section3\"></a>\n",
    "\n",
    "1. Function to data scrape an ESPN Fantasy Football league and store in json files\n",
    "2. Function to load scraped data from json files\n",
    "<br><br/>\n",
    "\n",
    "[Return to Top](#return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data ingestion class\n",
    "class data_ingest(object):\n",
    "    \n",
    "    # create __init__ function\n",
    "    def __init__(self, swid, espn_s2, league_id, season, week):\n",
    "        self.swid = swid\n",
    "        self.espn_s2 = espn_s2\n",
    "        self.league_id = league_id\n",
    "        self.season = season\n",
    "        self.week = week\n",
    "    \n",
    "    # create function to scrape espn data and save to json\n",
    "    def scrape_espn_data(self):\n",
    "        \n",
    "        # check whether the data path exists or not\n",
    "        isExist = os.path.exists(f'../data/{self.season}')\n",
    "\n",
    "        # if the data path doesn't exist...\n",
    "        if not isExist:\n",
    "            \n",
    "            # create a new directory\n",
    "            os.makedirs(f'../data/{self.season}')\n",
    "        \n",
    "        # create url.  there are multiple views we can look at but we're interested in matchup data\n",
    "        url = 'https://fantasy.espn.com/apis/v3/games/ffl/seasons/'+str(self.season)+'/segments/0/leagues/'+str(self.league_id)+'?view=mMatchup&view=mMatchupScore'\n",
    "        print(url)\n",
    "\n",
    "        # create JSON file for each week's matchup data\n",
    "        for i in range(1, self.week + 1):\n",
    "            print(f'season: {self.season}, week: {i}')\n",
    "            r = requests.get(url,\n",
    "                             params = {'scoringPeriodId': i},\n",
    "                             cookies = {\"SWID\": self.swid, \"espn_s2\": self.espn_s2})\n",
    "            d = r.json()\n",
    "            with open(f'../data/{self.season}/{self.season}_matchups_week_{i}.json', 'w', encoding = 'utf-8') as f:\n",
    "                json.dump(d, f, ensure_ascii = False, indent = 4)\n",
    "                \n",
    "    # create function to load json data from disk\n",
    "    def load_data_from_disk(self):\n",
    "        \n",
    "        # create empty list to store each week's matchups data\n",
    "        matchups_list = []\n",
    "        \n",
    "        # load JSON file for each's week matchups data\n",
    "        for i in range(1, self.week + 1):\n",
    "            f = open(f'../data/{self.season}/{self.season}_matchups_week_{i}.json')\n",
    "\n",
    "            # returns JSON object as a dictionary \n",
    "            data = json.load(f)\n",
    "\n",
    "            # add each JSON object to list created above\n",
    "            matchups_list.append(data)\n",
    "            \n",
    "        return matchups_list, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee397e73",
   "metadata": {},
   "source": [
    "## Functions for Rosters Dataframe <a id=\"section4\"></a>\n",
    "\n",
    "1. Function to create a dataframe with weekly rosters data and save it to csv\n",
    "2. Function to add the fantasy football scoring values to the weekly rosters dataframe \n",
    "<br><br/>\n",
    "\n",
    "[Return to Top](#return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rosters creation class\n",
    "class create_rosters(object):\n",
    "    \n",
    "    # create __init__ function\n",
    "    def __init__(self, matchups_list, season):\n",
    "        self.matchups_list = matchups_list\n",
    "        self.season = season\n",
    "        \n",
    "    # create function to create a dataframe with weekly roster data and save it to csv\n",
    "    def create_weekly_rosters(self):\n",
    "\n",
    "        # initialize list needed to create rosters_df\n",
    "        data_list = []\n",
    "\n",
    "        # loop through each JSON object in matchups_list which represents one week's matchup data\n",
    "        for wk in range(0, len(self.matchups_list)):\n",
    "\n",
    "            # grab year\n",
    "            year = self.matchups_list[wk]['seasonId']\n",
    "\n",
    "            # loop through each team\n",
    "            for tm in self.matchups_list[wk]['teams']:\n",
    "                owner_team_id   = tm['id']\n",
    "                owner_team_name = owner_team_codes[owner_team_id][0]\n",
    "                owner_name      = owner_team_codes[owner_team_id][1]\n",
    "\n",
    "                # loop through weekly roster\n",
    "                for p in tm['roster']['entries']:\n",
    "\n",
    "                    # grab week number\n",
    "                    temp_week = self.matchups_list[wk]['scoringPeriodId']\n",
    "\n",
    "                    # extract roster data\n",
    "                    player_name   = p['playerPoolEntry']['player']['fullName']\n",
    "                    slot_id       = p['lineupSlotId']\n",
    "                    slot_name     = lineup_slot_codes[slot_id]\n",
    "                    position_id   = p['playerPoolEntry']['player']['defaultPositionId']\n",
    "                    position_name = position_codes[position_id]\n",
    "\n",
    "                    # injured status (need try/exc bc of D/ST)\n",
    "                    current_inj = np.nan\n",
    "                    try:\n",
    "                        current_inj = p['playerPoolEntry']['player']['injuryStatus']\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    # projected/actual points\n",
    "                    # note:  need to grab team data in different locations within the json object since that data isn't always\n",
    "                    # in the same location.  data integrity issue\n",
    "                    proj_points, actual_points = None, None\n",
    "                    for stat in p['playerPoolEntry']['player']['stats']:\n",
    "                        if stat['scoringPeriodId'] != temp_week:\n",
    "                            continue\n",
    "                        if stat['statSourceId'] == 0:\n",
    "                            actual_points = stat['appliedTotal']\n",
    "                            if stat['proTeamId'] != 0:\n",
    "\n",
    "                                # grab team info\n",
    "                                pro_team_id = stat['proTeamId']\n",
    "                                pro_team_name = pro_team_codes[pro_team_id][0]\n",
    "                                pro_team_name_abv = pro_team_codes[pro_team_id][1]                        \n",
    "                        elif stat['statSourceId'] == 1:\n",
    "                            proj_points = stat['appliedTotal']\n",
    "                            if stat['proTeamId'] != 0:\n",
    "\n",
    "                                # grab team info\n",
    "                                pro_team_id = stat['proTeamId']\n",
    "                                pro_team_name = pro_team_codes[pro_team_id][0]\n",
    "                                pro_team_name_abv = pro_team_codes[pro_team_id][1]\n",
    "                            elif (proj_points < 1) & (not actual_points):\n",
    "\n",
    "                                # grab team info\n",
    "                                pro_team_id   = p['playerPoolEntry']['player']['proTeamId']\n",
    "                                pro_team_name = pro_team_codes[pro_team_id][0]\n",
    "                                pro_team_name_abv = pro_team_codes[pro_team_id][1] \n",
    "                            elif not pro_team_id:\n",
    "\n",
    "                                # grab team info\n",
    "                                pro_team_id   = p['playerPoolEntry']['player']['proTeamId']\n",
    "                                pro_team_name = pro_team_codes[pro_team_id][0]\n",
    "                                pro_team_name_abv = pro_team_codes[pro_team_id][1]                       \n",
    "\n",
    "                    # add data to list created above\n",
    "                    data_list.append([year, temp_week, owner_team_name, owner_name, player_name, pro_team_name, pro_team_name_abv, \n",
    "                                      current_inj, slot_name, position_name, proj_points, actual_points, slot_id])\n",
    "\n",
    "        # create rosters_df using data_list\n",
    "        rosters_df = pd.DataFrame(data_list, \n",
    "                                  columns=['year', 'week', 'owner_team', 'owner', 'player', 'pro_team', 'pro_team_abv',\n",
    "                                           'current_inj_status', 'lineup_slot_name', 'position_name', 'proj_points', \n",
    "                                           'actual_points', 'slot_id'\n",
    "                                          ]\n",
    "                                 )\n",
    "\n",
    "        # save to csv\n",
    "        rosters_df.to_csv(f\"../data/{self.season}/rosters_df_{self.season}.csv\", index = False)\n",
    "\n",
    "        # explore data frame\n",
    "        print(f'Weekly Rosters Shape: {rosters_df.shape}\\n')\n",
    "        display(rosters_df.info())\n",
    "        display(rosters_df.describe())\n",
    "        display(rosters_df.head())\n",
    "        \n",
    "        return rosters_df\n",
    "    \n",
    "    # create function to add the player stats and the fantasy football scoring stats to the rosters dataframe \n",
    "    def create_weekly_rosters_w_scoring(self, rosters_df):\n",
    "        \n",
    "        # create pandas dataframe using the fantasy football scoring dictionary's values as column names\n",
    "        ff_scoring_df = pd.DataFrame(np.zeros((len(rosters_df), len(ff_scoring_codes.values())))\n",
    "                                    ,columns = list(ff_scoring_codes.values()))\n",
    "\n",
    "        # create pandas dataframe using the player stat dictionary's values as column names\n",
    "        player_stat_df = pd.DataFrame(np.zeros((len(rosters_df), len(player_stat_codes.values())))\n",
    "                                     ,columns = list(player_stat_codes.values()))\n",
    "\n",
    "        # combine dataframe created above to the rosters dataframe\n",
    "        rosters_df_w_scoring = pd.concat([rosters_df, ff_scoring_df, player_stat_df], axis = 1)\n",
    "        \n",
    "        # loop through each JSON object in matchups_list which represents one week's matchup data\n",
    "        for wk in range(0, len(self.matchups_list)):\n",
    "\n",
    "            # grab year\n",
    "            year = self.matchups_list[wk]['seasonId']\n",
    "\n",
    "            # loop through each team\n",
    "            for tm in self.matchups_list[wk]['teams']:\n",
    "\n",
    "                # loop through weekly roster\n",
    "                for p in tm['roster']['entries']:\n",
    "                    #temp_week = wk + 1\n",
    "                    temp_week = self.matchups_list[wk]['scoringPeriodId']\n",
    "\n",
    "                    # grab player name\n",
    "                    player_name = p['playerPoolEntry']['player']['fullName']\n",
    "\n",
    "                    # loop through each set of stats\n",
    "                    for stat in p['playerPoolEntry']['player']['stats']:\n",
    "                        if stat['scoringPeriodId'] != temp_week:\n",
    "                            continue\n",
    "                        if stat['statSourceId'] == 0:\n",
    "\n",
    "                            # loop through the fantasy scoring stats\n",
    "                            for i in [int(s) for s in stat['appliedStats'].keys()]:\n",
    "\n",
    "                                # if the scoring code exists in the dictionary above then add the stat to rosters_df_w_scoring\n",
    "                                if i in ff_scoring_codes.keys():\n",
    "                                    rosters_df_w_scoring.loc[(rosters_df_w_scoring['player'] == player_name) & (rosters_df_w_scoring['week'] == temp_week) &\\\n",
    "                                                             (rosters_df_w_scoring['year'] == self.season), ff_scoring_codes[i]] = stat['appliedStats'][str(i)]\n",
    "\n",
    "                            # loop through the player stats\n",
    "                            for j in [int(r) for r in stat['stats'].keys()]:\n",
    "\n",
    "                                # if the scoring code exists in the dictionary above then add the stat to rosters_df_w_scoring\n",
    "                                if j in player_stat_codes.keys():\n",
    "                                    rosters_df_w_scoring.loc[(rosters_df_w_scoring['player'] == player_name) & (rosters_df_w_scoring['week'] == temp_week) &\\\n",
    "                                                             (rosters_df_w_scoring['year'] == self.season), player_stat_codes[j]] = stat['stats'][str(j)]\n",
    "\n",
    "        # replace nulls with 0\n",
    "        rosters_df_w_scoring.replace(np.nan, 0, inplace=True)\n",
    "        \n",
    "        # save to csv\n",
    "        rosters_df_w_scoring.to_csv(f\"../data/{self.season}/rosters_df_w_scoring_{self.season}.csv\", index = False)\n",
    "\n",
    "        # explore data frame\n",
    "        print(f'Weekly Rosters Shape w/ Scoring: {rosters_df_w_scoring.shape}\\n')\n",
    "        display(rosters_df_w_scoring.info())\n",
    "        display(rosters_df_w_scoring.describe())\n",
    "        display(rosters_df_w_scoring.head())\n",
    "        \n",
    "        return rosters_df_w_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60803021",
   "metadata": {},
   "source": [
    "## Functions for Matchups Dataframe <a id=\"section5\"></a>\n",
    "\n",
    "1. Function to create a dataframe with weekly matchups data and save it to csv\n",
    "2. Function to create a dataframe with total wins/losses through the most recent NFL week and save it to csv\n",
    "<br><br/>\n",
    "\n",
    "[Return to Top](#return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data ingestion class\n",
    "class create_matchups(object):\n",
    "    \n",
    "    # create __init__ function\n",
    "    def __init__(self, season):\n",
    "        self.season = season\n",
    "    \n",
    "    # create function to each fantasy football teams' weekly matchups and save it to a csv file\n",
    "    def create_weekly_matchups(self, data):\n",
    "        \n",
    "        # initialize list needed to create matchups dataframe\n",
    "        data_list = []\n",
    "\n",
    "        # loop through each matchup from week 1 to current week\n",
    "        for i in range(0, len(data['schedule'])):\n",
    "            \n",
    "            # check if there was actually a winner\n",
    "            if data['schedule'][i]['winner'] == 'UNDECIDED':\n",
    "                continue\n",
    "\n",
    "            # create zipped dictionary for each scoring period since there may be multiple scoring periods within each matchup period (i.e 2 week playoff matchups)\n",
    "            zip_dict = zip(enumerate(data['schedule'][i]['away']['pointsByScoringPeriod'].items()),\\\n",
    "                           enumerate(data['schedule'][i]['home']['pointsByScoringPeriod'].items())\n",
    "                          )\n",
    "\n",
    "            # loop through each item in zip_dict\n",
    "            for (index_away, (key_away, value_away)), (index_home, (key_home, value_home)) in zip_dict:\n",
    "\n",
    "                # build row for away team\n",
    "                away_week = int(key_away)\n",
    "                away_owner_team_id = data['schedule'][i]['away']['teamId']\n",
    "                away_owner_team_name = owner_team_codes[away_owner_team_id][0]\n",
    "                away_owner_name = owner_team_codes[away_owner_team_id][1]\n",
    "                away_score = float(value_away)\n",
    "                away_opp_id = data['schedule'][i]['home']['teamId']\n",
    "                away_opp_team_name = owner_team_codes[away_opp_id][0]\n",
    "                away_opp_name = owner_team_codes[away_opp_id][1]\n",
    "                away_opp_score = float(value_home)\n",
    "\n",
    "                # check if is more than one scoring period\n",
    "                if len(data['schedule'][i]['away']['pointsByScoringPeriod']) > 1:\n",
    "\n",
    "                    # determine if away team won and only assign the win when looping through the last scoring period in a matchup period\n",
    "                    if index_away == 1 and data['schedule'][i]['winner'] == 'AWAY':\n",
    "                        away_win = 1\n",
    "                    else:\n",
    "                        away_win = 0\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # determine if away team won\n",
    "                    if data['schedule'][i]['winner'] == 'AWAY':\n",
    "                        away_win = 1\n",
    "                    else:\n",
    "                        away_win = 0\n",
    "\n",
    "                # append away row to data_list\n",
    "                data_list.append([away_week, away_owner_team_name, away_owner_name, away_score, away_win, away_opp_team_name, \n",
    "                                  away_opp_name, away_opp_score])\n",
    "\n",
    "                # build row for home team\n",
    "                home_week = int(key_home)\n",
    "                home_owner_team_id = data['schedule'][i]['home']['teamId']\n",
    "                home_owner_team_name = owner_team_codes[home_owner_team_id][0]\n",
    "                home_owner_name = owner_team_codes[home_owner_team_id][1]\n",
    "                home_score = float(value_home)\n",
    "                home_opp_id = data['schedule'][i]['away']['teamId']\n",
    "                home_opp_team_name = owner_team_codes[home_opp_id][0]\n",
    "                home_opp_name = owner_team_codes[home_opp_id][1]\n",
    "                home_opp_score = float(value_away)\n",
    "\n",
    "                # check if is more than one scoring period\n",
    "                if len(data['schedule'][i]['home']['pointsByScoringPeriod']) > 1:\n",
    "\n",
    "                    # determine if home team won and only assign the win when looping through the last scoring period in a matchup period  \n",
    "                    if index_home == 1 and data['schedule'][i]['winner'] == 'HOME':\n",
    "                        home_win = 1\n",
    "                    else:\n",
    "                        home_win = 0\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # determine if home team won    \n",
    "                    if data['schedule'][i]['winner'] == 'HOME':\n",
    "                        home_win = 1\n",
    "                    else:\n",
    "                        home_win = 0\n",
    "\n",
    "                # append home row to data_list\n",
    "                data_list.append([home_week, home_owner_team_name, home_owner_name, home_score, home_win, home_opp_team_name, \n",
    "                                  home_opp_name, home_opp_score])\n",
    "\n",
    "        # create matchups_df using data_list\n",
    "        matchups_df = pd.DataFrame(data_list, \n",
    "                                   columns=['week', 'owner_team_name', 'owner', 'score', 'win', 'opp_owner_team_name', 'opp_owner', \n",
    "                                            'opp_score'])\n",
    "        # save to csv\n",
    "        matchups_df.to_csv(f\"../data/{self.season}/matchups_df_{self.season}.csv\", index = False)\n",
    "        \n",
    "        # explore data frame\n",
    "        print(f'Weekly Matchups Shape: {matchups_df.shape}\\n')\n",
    "        display(matchups_df.info())\n",
    "        display(matchups_df.describe())\n",
    "        display(matchups_df.head())\n",
    "        \n",
    "        return matchups_df\n",
    "    \n",
    "    # create function to create dataframe of total wins/losses by fantasy football team\n",
    "    def create_wins_losses(self, matchups_df: object):\n",
    "    \n",
    "        # subset matchups_df by wins\n",
    "        wins = matchups_df.loc[matchups_df['win'] == 1]\n",
    "\n",
    "        # create total_wins dataframe of wins per team\n",
    "        total_wins = pd.DataFrame(wins.groupby(['owner_team_name'])['win'].value_counts().reset_index(0).reset_index(drop=True))\n",
    "        total_wins.columns = ['owner_team_name', 'wins']\n",
    "\n",
    "        # subset matchups_df by losses\n",
    "        losses = matchups_df.loc[matchups_df['win'] == 0]\n",
    "\n",
    "        # create total_losses dataframe of losses per team\n",
    "        total_losses = pd.DataFrame(losses.groupby(['owner_team_name'])['win'].value_counts().reset_index(0).reset_index(drop=True))\n",
    "        total_losses.columns = ['owner_team_name', 'losses']\n",
    "\n",
    "        # merge total_wins and total_losses\n",
    "        win_loss_df = total_wins.merge(total_losses, on = 'owner_team_name', how = 'left')\n",
    "\n",
    "        # replace any null values with 0 which means one or more teams have either 0 wins or 0 losses\n",
    "        win_loss_df.fillna(0, inplace=True)\n",
    "\n",
    "        # fillna function casts dtype to float so change dtype back to int\n",
    "        win_loss_df['losses'] = win_loss_df['losses'].astype('int')\n",
    "        win_loss_df['wins'] = win_loss_df['wins'].astype('int')\n",
    "\n",
    "        # # create total_points dataframe of wins per team\n",
    "        total_points_df = pd.DataFrame(matchups_df.groupby(['owner_team_name'])[['score', 'opp_score']].sum().reset_index(0).reset_index(drop=True))\n",
    "        total_points_df.columns = ['owner_team_name', 'points_for', 'points_against']\n",
    "\n",
    "        # merge win_loss_df with total_points_df\n",
    "        win_loss_df = win_loss_df.merge(total_points_df, on = 'owner_team_name', how = 'left')\n",
    "\n",
    "        # save to csv\n",
    "        win_loss_df.to_csv(f\"../data/{self.season}/win_loss_df_{self.season}.csv\", index = False)\n",
    "        \n",
    "        # explore data frame\n",
    "        print(f'Total Wins/Losses Shape: {win_loss_df.shape}\\n')\n",
    "        display(win_loss_df.info())\n",
    "        display(win_loss_df.describe())\n",
    "        display(win_loss_df.head())\n",
    "        \n",
    "        return win_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96ef0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
